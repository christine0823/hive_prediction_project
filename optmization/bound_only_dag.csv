hive.merge.size.per.task,128000000,256000000,64000000,int,hive
mapreduce.job.reduces,1,1,1,int,hadoop
mapreduce.job.jvm.numtasks,1,1,1,int,hadoop
hive.map.aggr,0,1,1,str,hive
hive.fetch.task.conversion,0,2,1,str,hive
hive.auto.convert.join.noconditionaltask,0,1,1,str,hive
hive.auto.convert.sortmerge.join,0,1,1,str,hive
hive.groupby.skewindata,0,1,1,str,hive
hive.auto.convert.join,0,1,1,str,hive
hive.mapjoin.smalltable.filesize,20000000,100000000,10000000,int,hive
hive.exec.compress.output,0,1,1,int,hive
hive.exec.compress.intermediate,0,1,1,int,hive
hive.metastore.server.max.threads,500,1000,100,int,hive
hive.mapred.reduce.tasks.speculative.execution,0,1,1,str,hive
hive.vectorized.execution.enabled,0,1,1,str,hive
hive.exec.mode.local.auto,0,1,1,str,hive
hive.optimize.correlation,0,1,1,str,hive
mapreduce.tasktracker.map.tasks.maximum,2,2,1,int,hadoop
mapreduce.tasktracker.reduce.tasks.maximum,2,2,1,int,hadoop
mapreduce.task.io.sort.mb,100,100,1,int,hadoop
mapreduce.task.io.sort.factor,10,10,1,int,hadoop
mapreduce.reduce.shuffle.parallelcopies,5,5,1,int,hadoop
mapreduce.reduce.shuffle.input.buffer.percent,0.7,0.7,0,float,hadoop
mapreduce.reduce.shuffle.merge.percent,0.66,0.66,0,float,hadoop
mapreduce.reduce.shuffle.memory.limit.percent,0.25,0.25,0,float,hadoop
mapreduce.map.sort.spill.percent,0.8,0.8,0.0,float,hadoop
mapreduce.reduce.input.buffer.percent,0.0,0.0,0.1,float,hadoop
mapreduce.reduce.merge.inmem.threshold,1000,1000,1,int,hadoop
mapreduce.job.reduce.slowstart.completedmaps,0.05,0.05,0.05,float,hadoop
mapreduce.jobtracker.handler.count,10,10,1,int,hadoop
mapreduce.tasktracker.http.threads,40,40,1,int,hadoop
mapreduce.map.cpu.vcores,1,1,1,int,hadoop
mapreduce.reduce.cpu.vcores,1,1,1,int,hadoop
mapreduce.map.memory.mb,1024,1024,1,int,hadoop
mapreduce.reduce.memory.mb,1024,1024,1,int,hadoop
yarn.app.mapreduce.am.resource.mb,1536,1536,1,int,hadoop
yarn.app.mapreduce.am.resource.cpu-vcores,1,1,1,int,hadoop
mapreduce.map.output.compress,0,0,1,int,hadoop
mapreduce.output.fileoutputformat.compress,0,0,1,int,hadoop
mapreduce.output.fileoutputformat.compress.type,1,1,1,int,hadoop
mapred.child.java.opts,200,200,1,int,hadoop
